{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshallPotts/CSE450-Machine-Learning/blob/main/Module6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aUB4xrFdLkr8"
      },
      "outputs": [],
      "source": [
        "restart = True\n",
        "epoch_to_pickup = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XtiXE04uGB_U"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import contextlib\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "import gc  # Import the garbage collector module\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUgiww4oQ75T",
        "outputId": "794a3f82-0511-4221-c98f-65cb359a7a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "irakMtGnaImf"
      },
      "outputs": [],
      "source": [
        "path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nDl6_okDOUyY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# path = '/content/drive/My Drive/M6_Fall2023e/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv4r-dKnSRKz"
      },
      "source": [
        "## Functions for downloading text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceSpeakerNames(text):\n",
        "    \"\"\"\n",
        "    Replaces speaker names\n",
        "    \"\"\"\n",
        "   # speaker_names = [\"KIRK:\", \"SPOCK:\", \"MCCOY:\", \"SCOTTY:\", \"UHURA:\", \"SULU:\", \"CHEKOV:\"]\n",
        "   # for speaker in speaker_names:\n",
        "   #     text = re.sub(re.escape(speaker), \"*CHARACTER*:\", text)\n",
        "    text = re.sub(\"Desaille\", \"Desalle\", text, re.IGNORECASE)\n",
        "    return text"
      ],
      "metadata": {
        "id": "cJ2x6RMk3Dkt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xzLUaBa2Xmnb"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    #remove names from dialog titles that are used too often\n",
        "    text = replaceSpeakerNames(text)\n",
        "\n",
        "\n",
        "    # Remove carriage returns\n",
        "    text = text.replace(\"\\r\", \"\")\n",
        "\n",
        "    # fix quotes\n",
        "    text = text.replace(\"“\", \"\\\"\")\n",
        "    text = text.replace(\"”\", \"\\\"\")\n",
        "\n",
        "    # Replace any capital letter at the start of a word with ^ followed by the lowercase letter\n",
        "    text = re.sub(r\"(?<![a-zA-Z])([A-Z])\", lambda match: f\"^{match.group(0).lower()}\", text)\n",
        "\n",
        "    # Replace all other capital letters with lowercase\n",
        "    text = re.sub(r\"([A-Z])\", lambda match: f\"{match.group(0).lower()}\", text)\n",
        "\n",
        "    # Remove duplicate whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
        "    text = re.sub(r\"\\t+\", \"\\t\", text)\n",
        "\n",
        "    # Replace whitespace characters with special words\n",
        "    text = re.sub(r\"(\\t)\", r\" zztabzz \", text)\n",
        "    text = re.sub(r\"(\\n)\", r\" zznewlinezz \", text)\n",
        "    text = re.sub(r\"(\\s)\", r\" zzspacezz \", text)\n",
        "\n",
        "    # Split before and after punctuation\n",
        "    for punctuation in string.punctuation:\n",
        "        text = text.replace(punctuation, f\" {punctuation} \")\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nFKehxVF9AxD"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(text):\n",
        "\n",
        "    # Replace special words with whitespace characters\n",
        "    text = text.replace(\"zztabzz\", \"\\t\")\n",
        "    text = text.replace(\"zznewlinezz\", \"\\n\")\n",
        "    text = text.replace(\"zzspacezz\", \" \")\n",
        "\n",
        "    # Remake capital letters at beginning of words\n",
        "    text = re.sub(r\"\\^([a-z])\", lambda match: f\"{match.group(1).upper()}\", text)\n",
        "\n",
        "    text = text.replace(\"^\", \"\")\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Rtd9QyvUWqzi"
      },
      "outputs": [],
      "source": [
        "# def getMyText():\n",
        "#   path_to_file = tf.keras.utils.get_file('austen.txt', 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/austen/austen.txt')\n",
        "\n",
        "#   text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "#   # path_to_file = tf.keras.utils.get_file('903-0.txt', 'https://www.gutenberg.org/files/903/903-0.txt')\n",
        "#   # author_text += open(path_to_file, 'rb').read().decode(encoding='utf-8')[2999:-19194]\n",
        "#   # tf.io.gfile.remove(path_to_file)\n",
        "\n",
        "#   return preprocess_text(text)\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def getMyText():\n",
        "    local_path = \"./cleaned_TOS_Scripts.txt\"\n",
        "\n",
        "    try:\n",
        "        with open(local_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "        return preprocess_text(text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###View the Text"
      ],
      "metadata": {
        "id": "qprtceI71k-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_example = getMyText()\n",
        "# Write the example text back to a new file\n",
        "with open(\"example_scripts.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(text_example)\n",
        "    getMyText()"
      ],
      "metadata": {
        "id": "rofy7hJ1iHVm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def getRandomText(file_path=\"cleaned_TOS_Scripts.txt\", chunk_size=200000, verbose=False):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        # Ensure text is long enough\n",
        "        if len(text) < chunk_size:\n",
        "            raise ValueError(\"Text file is too short to extract a random chunk.\")\n",
        "\n",
        "        # Pick a random starting position\n",
        "        start_idx = random.randint(0, len(text) - chunk_size)\n",
        "        text_random = text[start_idx: start_idx + chunk_size]\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Extracted a random chunk from position {start_idx}\")\n",
        "\n",
        "        return preprocess_text(text_random)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "3knXkWserF7Y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vjEF0LKxhljS"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocab_text = getMyText()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpFvtyF_g3jY"
      },
      "source": [
        "Make vocabulary (Adapted from TensorFlow word embedding tutorial)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "F8E6Q6dkMEpd"
      },
      "outputs": [],
      "source": [
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 8192\n",
        "sequence_length = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AWXUqLQ6g3KB"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  # Use the text vectorization layer to normalize, split, and map strings to\n",
        "  # integers. Note that the layer uses the custom standardization defined above.\n",
        "  # Set maximum_sequence length as all samples are not of the same length.\n",
        "  vectorize_layer = TextVectorization(\n",
        "      standardize='lower',\n",
        "      split='whitespace',\n",
        "      max_tokens=vocab_size,\n",
        "      output_mode='int',\n",
        "      #output_sequence_length=sequence_length\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "zJfr5w1bTWiJ"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  # Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "  vectorize_layer.adapt([vocab_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PmaoiyvF1Ilm"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocabulary = vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7ULNtM_8nYn"
      },
      "source": [
        "Save Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "G1hjxv447INt"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  with open(path + \"vocabulary.txt\", \"w\") as file:\n",
        "    for word in vocabulary:\n",
        "        file.write(word + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7qn5MjC8p0_"
      },
      "source": [
        "Load Saved Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TLbSoqUP8Pxu"
      },
      "outputs": [],
      "source": [
        "if restart == False:\n",
        "  with open(path + \"vocabulary.txt\", \"r\") as file:\n",
        "      vocabulary = [word.strip() for word in file.readlines()]\n",
        "      vocabulary = vocabulary\n",
        "\n",
        "  vectorize_layer = TextVectorization(\n",
        "      vocabulary=vocabulary,\n",
        "      standardize='lower',\n",
        "      split='whitespace',\n",
        "      max_tokens=vocab_size,\n",
        "      output_mode='int',\n",
        "      #output_sequence_length=sequence_length\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FidGlurb1iD3",
        "outputId": "f783f330-3afc-407d-be64-080c0397ae72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', np.str_('zzspacezz'), np.str_('^'), np.str_('.'), np.str_(':'), np.str_(','), np.str_('the'), np.str_(\"'\"), np.str_('you'), np.str_('kirk'), np.str_('to'), np.str_('i'), np.str_('a'), np.str_('?'), np.str_('spock'), np.str_('of'), np.str_('it'), np.str_('and'), np.str_('s')]\n",
            "[np.str_('medication'), np.str_('mediaeval'), np.str_('meddling'), np.str_('mechanized'), np.str_('mechanization'), np.str_('mechanics'), np.str_('measuring'), np.str_('meandering'), np.str_('mcgiver'), np.str_('maze'), np.str_('mature'), np.str_('mating'), np.str_('materialization'), np.str_('mated'), np.str_('masked'), np.str_('martini'), np.str_('marshals'), np.str_('marshall'), np.str_('mars'), np.str_('marks')]\n"
          ]
        }
      ],
      "source": [
        "print(vocabulary[:20])\n",
        "print(vocabulary[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LovypAGk91Yp"
      },
      "source": [
        "Turn text into a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Mnp0huUX93Wi"
      },
      "outputs": [],
      "source": [
        "# This function will generate our sequence pairs:\n",
        "def split_input_target(sequence):\n",
        "    input_ids = sequence[:-1]\n",
        "    target_ids = sequence[1:]\n",
        "    return input_ids, target_ids\n",
        "\n",
        "# This function will create the dataset\n",
        "def text_to_dataset(text):\n",
        "  all_ids = vectorize_layer(text)\n",
        "  ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "  del all_ids\n",
        "  sequences = ids_dataset.batch(sequence_length+1, drop_remainder=True)\n",
        "  del ids_dataset\n",
        "\n",
        "  # Call the function for every sequence in our list to create a new dataset\n",
        "  # of input->target pairs\n",
        "  dataset = sequences.map(split_input_target)\n",
        "  del sequences\n",
        "\n",
        "  # shuffle\n",
        "\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afRybxef_QHi"
      },
      "source": [
        "Test on vocab text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "0tBa6ttN_Ufz"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocab_ds = text_to_dataset(vocab_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vq191mRgWv2w"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  text = ''.join([vocabulary[index] for index in ids])\n",
        "  return postprocess_text(text)\n",
        "\n",
        "vocabulary_adjusted = vocabulary\n",
        "vocabulary_adjusted[0] = '[UNK]'\n",
        "vocabulary_adjusted[1] = ''\n",
        "\n",
        "words_from_ids = tf.keras.layers.StringLookup(vocabulary=vocabulary_adjusted, invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDqaTHXFAEBD",
        "outputId": "c1c2007b-31a9-455e-e1a4-21ae519cddfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "tf.Tensor(\n",
            "[   3    7    2    3 1668    2    3    1    2 2844    2   23    3   76\n",
            "   22    2    3   15    5    2    3  406    2    7    2 1415    4    2\n",
            "    3 1270    5    2    3   44    2 1646    6    2   54    4    2    3\n",
            "   15    5    2    3   17    2   48    8   29    2   34    2    7    2\n",
            "  377    2  103    4    2    3 1214    2  147    2   61    2   47    6\n",
            "    2    3   28    6    2 1651    2   35    2  137    4    2    3 1270\n",
            "    5    2    3   17    2  110    2   34    2  178    2    1    4    2\n",
            "    3   58    5    2    3   41    6    2   17    8   19    2  147    2\n",
            "  412    4    2    3   47    8   19    2  163    2  147    2   61    2\n",
            "   47    4], shape=(128,), dtype=int64)\n",
            "The Cage  pilot [Bridge] Spock: Check the circuit. Tyler: All operating, sir. Spock: It can't be the screen then. Definitely something out there, Captain, headed this way. Tyler: It could be these . One: No, it's something else. There's still something out there.\n",
            "tf.Tensor(\n",
            "[b'^' b'the' b'zzspacezz' b'^' b'cage' b'zzspacezz' b'^' b'' b'zzspacezz'\n",
            " b'pilot' b'zzspacezz' b'[' b'^' b'bridge' b']' b'zzspacezz' b'^' b'spock'\n",
            " b':' b'zzspacezz' b'^' b'check' b'zzspacezz' b'the' b'zzspacezz'\n",
            " b'circuit' b'.' b'zzspacezz' b'^' b'tyler' b':' b'zzspacezz' b'^' b'all'\n",
            " b'zzspacezz' b'operating' b',' b'zzspacezz' b'sir' b'.' b'zzspacezz' b'^'\n",
            " b'spock' b':' b'zzspacezz' b'^' b'it' b'zzspacezz' b'can' b\"'\" b't'\n",
            " b'zzspacezz' b'be' b'zzspacezz' b'the' b'zzspacezz' b'screen'\n",
            " b'zzspacezz' b'then' b'.' b'zzspacezz' b'^' b'definitely' b'zzspacezz'\n",
            " b'something' b'zzspacezz' b'out' b'zzspacezz' b'there' b',' b'zzspacezz'\n",
            " b'^' b'captain' b',' b'zzspacezz' b'headed' b'zzspacezz' b'this'\n",
            " b'zzspacezz' b'way' b'.' b'zzspacezz' b'^' b'tyler' b':' b'zzspacezz'\n",
            " b'^' b'it' b'zzspacezz' b'could' b'zzspacezz' b'be' b'zzspacezz' b'these'\n",
            " b'zzspacezz' b'' b'.' b'zzspacezz' b'^' b'one' b':' b'zzspacezz' b'^'\n",
            " b'no' b',' b'zzspacezz' b'it' b\"'\" b's' b'zzspacezz' b'something'\n",
            " b'zzspacezz' b'else' b'.' b'zzspacezz' b'^' b'there' b\"'\" b's'\n",
            " b'zzspacezz' b'still' b'zzspacezz' b'something' b'zzspacezz' b'out'\n",
            " b'zzspacezz' b'there' b'.'], shape=(128,), dtype=string)\n",
            "Target: \n",
            "tf.Tensor(\n",
            "[   7    2    3 1668    2    3    1    2 2844    2   23    3   76   22\n",
            "    2    3   15    5    2    3  406    2    7    2 1415    4    2    3\n",
            " 1270    5    2    3   44    2 1646    6    2   54    4    2    3   15\n",
            "    5    2    3   17    2   48    8   29    2   34    2    7    2  377\n",
            "    2  103    4    2    3 1214    2  147    2   61    2   47    6    2\n",
            "    3   28    6    2 1651    2   35    2  137    4    2    3 1270    5\n",
            "    2    3   17    2  110    2   34    2  178    2    1    4    2    3\n",
            "   58    5    2    3   41    6    2   17    8   19    2  147    2  412\n",
            "    4    2    3   47    8   19    2  163    2  147    2   61    2   47\n",
            "    4    2], shape=(128,), dtype=int64)\n",
            "the Cage  pilot [Bridge] Spock: Check the circuit. Tyler: All operating, sir. Spock: It can't be the screen then. Definitely something out there, Captain, headed this way. Tyler: It could be these . One: No, it's something else. There's still something out there. \n"
          ]
        }
      ],
      "source": [
        "if restart:\n",
        "  for input_example, target_example in vocab_ds.take(1):\n",
        "    print(\"Input: \")\n",
        "    print(input_example)\n",
        "    print(text_from_ids(input_example))\n",
        "    print(words_from_ids(input_example))\n",
        "    print(\"Target: \")\n",
        "    print(target_example)\n",
        "    print(text_from_ids(target_example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Rp402vgrS54t"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "def setup_dataset(dataset):\n",
        "  dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0LdoMfT7T8WN"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocab_ds = setup_dataset(vocab_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VQ-KjEeZMzd"
      },
      "source": [
        "## III. Build the model\n",
        "\n",
        "Next, we'll build our model. Up until this point, you've been using the Keras symbolic, or imperative API for creating your models. Doing something like:\n",
        "\n",
        "    model = tf.keras.models.Sequentla()\n",
        "    model.add(tf.keras.layers.Dense(80, activation='relu))\n",
        "    etc...\n",
        "\n",
        "However, tensorflow has another way to build models called the Functional API, which gives us a lot more control over what happens inside the model. You can read more about [the differences and when to use each here](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html).\n",
        "\n",
        "We'll use the functional API for our RNN in this example. This will involve defining our model as a custom subclass of `tf.keras.Model`.\n",
        "\n",
        "If you're not familiar with classes in python, you might want to review [this quick tutorial](https://www.w3schools.com/python/python_classes.asp), as well as [this one on class inheritance](https://www.w3schools.com/python/python_inheritance.asp).\n",
        "\n",
        "Using a functional model is important for our situation because we're not just training it to predict a single character for a single sequence, but as we make predictions with it, we need it to remember those predictions as use that memory as it makes new predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Fj4uh9y-Y9mx"
      },
      "outputs": [],
      "source": [
        "# Create our custom model. Given a sequence of characters, this\n",
        "# model's job is to predict what character should come next.\n",
        "class TOStextModel(tf.keras.Model):\n",
        "\n",
        "  # This is our class constructor method, it will be executed when\n",
        "  # we first create an instance of the class\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__()\n",
        "\n",
        "    # Our model will have three layers:\n",
        "\n",
        "    # 1. An embedding layer that handles the encoding of our vocabulary into\n",
        "    #    a vector of values suitable for a neural network\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # 2. A GRU layer that handles the \"memory\" aspects of our RNN. If you're\n",
        "    #    wondering why we use GRU instead of LSTM, and whether LSTM is better,\n",
        "    #    take a look at this article: https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm\n",
        "    #    then consider trying out LSTM instead (or in addition to!)\n",
        "    #self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
        "    self.lstm1 = tf.keras.layers.LSTM(rnn_units, recurrent_regularizer=\"l2\", return_sequences=True, return_state=True)\n",
        "    self.lstm2 = tf.keras.layers.LSTM(rnn_units, recurrent_regularizer=\"l2\", return_sequences=True, return_state=True)\n",
        "    self.lstm3 = tf.keras.layers.LSTM(rnn_units, recurrent_regularizer=\"l2\", return_sequences=True, return_state=True)\n",
        "    #self.lstm4 = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "\n",
        "\n",
        "    self.hidden1 = tf.keras.layers.Dense(embedding_dim*64, kernel_regularizer=\"l2\", activation='relu')\n",
        "    self.hidden2 = tf.keras.layers.Dense(embedding_dim*16, kernel_regularizer=\"l1\", activation='relu')\n",
        "    #self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "    #self.hidden3 = tf.keras.layers.Dense(embedding_dim*4, activation='relu')\n",
        "\n",
        "    # 3. Our output layer that will give us a set of probabilities for each\n",
        "    #    character in our vocabulary.\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  # This function will be executed for each epoch of our training. Here\n",
        "  # we will manually feed information from one layer of our network to the\n",
        "  # next.\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    # 1. Feed the inputs into the embedding layer, and tell it if we are\n",
        "    #    training or predicting\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    # 2. If we don't have any state in memory yet, get the initial random state\n",
        "    #    from our GRUI layer.\n",
        "    batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "    if states is None:\n",
        "      states1 = [tf.zeros([batch_size, self.lstm1.units]), tf.zeros([batch_size, self.lstm1.units])]\n",
        "      states2 = [tf.zeros([batch_size, self.lstm2.units]), tf.zeros([batch_size, self.lstm2.units])]\n",
        "      states3 = [tf.zeros([batch_size, self.lstm3.units]), tf.zeros([batch_size, self.lstm3.units])]\n",
        "      #states4 = [tf.zeros([batch_size, self.lstm4.units]), tf.zeros([batch_size, self.lstm4.units])]\n",
        "    else:\n",
        "      states1 = states[0]\n",
        "      states2 = states[1]\n",
        "      states3 = states[2]\n",
        "      #states4 = states[3]\n",
        "    # 3. Now, feed the vectorized input along with the current state of memory\n",
        "    #    into the gru layer.\n",
        "    x, state_h_1, state_c_1 = self.lstm1(x, initial_state=states1, training=training)\n",
        "    states_out_1 = [state_h_1,state_c_1]\n",
        "\n",
        "    x, state_h_2, state_c_2 = self.lstm2(x, initial_state=states2, training=training)\n",
        "    states_out_2 = [state_h_2,state_c_2]\n",
        "\n",
        "    x, state_h_3, state_c_3 = self.lstm3(x, initial_state=states3, training=training)\n",
        "    states_out_3 = [state_h_3,state_c_3]\n",
        "\n",
        "    #x, state_h_4, state_c_4 = self.lstm4(x, initial_state=states4, training=training)\n",
        "    #states_out_4 = [state_h_4,state_c_4]\n",
        "\n",
        "    states_out = [states_out_1, states_out_2, states_out_3]#, states_out_4]\n",
        "    #states_out = [states_out_1, states_out_2]\n",
        "\n",
        "    x = self.hidden1(x,training=training)\n",
        "    x = self.hidden2(x,training=training)\n",
        "    #x = self.hidden3(x,training=training)\n",
        "    # 4. Finally, pass the results on to the dense layer\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    # 5. Return the results\n",
        "    if return_state:\n",
        "      return x, states_out\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "NGm9o_J8Tq2F"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  dataset = vocab_ds\n",
        "  del vocab_text\n",
        "  del vocab_ds\n",
        "else:\n",
        "  new_text = getRandomText(numbooks = 10)\n",
        "  dataset = text_to_dataset(new_text)\n",
        "  del new_text\n",
        "  dataset = setup_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "UA2C6pxZc4De"
      },
      "outputs": [],
      "source": [
        "# Create an instance of our model\n",
        "#vocab_size=len(ids_from_chars.get_vocabulary())\n",
        "embedding_dim = 128\n",
        "rnn_units = 512\n",
        "\n",
        "model = TOStextModel(vocab_size, embedding_dim, rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C67kN7YAdfSf",
        "outputId": "e2e423fd-7115-4f48-e652-563cfd36c4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 8192) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Verify the output of our model is correct by running one sample through\n",
        "# This will also compile the model for us. This step will take a bit.\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "qJGL8gCWdsiu",
        "outputId": "f63d0f21-7d74-46cd-9277-a6072d8e1f9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"to_stext_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"to_stext_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │       \u001b[38;5;34m1,048,576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m), │       \u001b[38;5;34m1,312,768\u001b[0m │\n",
              "│                                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m), │       \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "│                                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m), │       \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "│                                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8192\u001b[0m)             │       \u001b[38;5;34m4,202,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2048\u001b[0m)             │      \u001b[38;5;34m16,779,264\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8192\u001b[0m)             │      \u001b[38;5;34m16,785,408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │\n",
              "│                                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "│                                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "│                                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,202,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,779,264</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,785,408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,326,912\u001b[0m (169.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,326,912</span> (169.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,326,912\u001b[0m (169.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,326,912</span> (169.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Now let's view the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "UDbtrI9tc2NH"
      },
      "outputs": [],
      "source": [
        "# Here's the code we'll use to sample for us. It has some extra steps to apply\n",
        "# the temperature to the distribution, and to make sure we don't get empty\n",
        "# characters in our text. Most importantly, it will keep track of our model\n",
        "# state for us.\n",
        "\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, vectorize_layer, vocabulary, temperature=2):\n",
        "    super().__init__()\n",
        "    self.temperature=temperature\n",
        "    self.model = model\n",
        "    self.vectorize_layer = vectorize_layer\n",
        "    self.vocabulary = vocabulary\n",
        "    #print(\"initialized\")\n",
        "\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    skip_ids = StringLookup(vocabulary=list(vocabulary))(['', '[UNK]'])[:, None]\n",
        "    #print(skip_ids)\n",
        "    #print(\"3\")\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices = skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(vocabulary)])\n",
        "    #print(\"4\")\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask,validate_indices=False)\n",
        "    #print(\"5\")\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    #input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.vectorize_layer(inputs)\n",
        "    #print(input_ids)\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states =  self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    del input_ids\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    del predicted_logits\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    #print(predicted_ids[0])\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return words_from_ids(predicted_ids), states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "P3WQoFaE7Ol2"
      },
      "outputs": [],
      "source": [
        "def produce_sample(model, vectorize_layer, vocabulary, temp, epoch, prompt):\n",
        "  # Create an instance of the character generator\n",
        "  #print(\"entered\")\n",
        "  one_step_model = OneStep(model, vectorize_layer, vocabulary, temp)\n",
        "  #print(\"rand one step\")\n",
        "  # Now, let's generate a 1000 character chapter by giving our model \"Chapter 1\"\n",
        "  # as its starting text\n",
        "  states = None\n",
        "  next_char = tf.constant([preprocess_text(prompt)])\n",
        "  result = [tf.constant([prompt])]\n",
        "\n",
        "  for n in range(200):\n",
        "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "    #print(next_char)\n",
        "    result.append(next_char)\n",
        "    #print(result)\n",
        "\n",
        "  result = tf.strings.join(result)\n",
        "  #print(result)\n",
        "\n",
        "  # Print the results formatted.\n",
        "  #print('Temp: ' + str(temp) + '\\n')\n",
        "  print(postprocess_text(result[0].numpy().decode('utf-8')))\n",
        "  #print('\\n\\n')\n",
        "  print('Epoch: ' + str(epoch) + '\\n', file=open(path + 'tree.txt', 'a'))\n",
        "  print('Temp: ' + str(temp) + '\\n', file=open(path + 'tree.txt', 'a'))\n",
        "  print(postprocess_text(result[0].numpy().decode('utf-8')), file=open(path + 'tree.txt', 'a'))\n",
        "  print('\\n\\n', file=open(path + 'tree.txt', 'a'))\n",
        "  del states\n",
        "  del next_char\n",
        "  del result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTDe5m4baEqo"
      },
      "source": [
        "## IV. Train the model\n",
        "\n",
        "For our purposes, we'll be using [categorical cross entropy](https://machinelearningmastery.com/cross-entropy-for-machine-learning/) as our loss function*. Also, our model will be outputting [\"logits\" rather than normalized probabilities](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow), because we'll be doing further transformations on the output later.\n",
        "\n",
        "\n",
        "\\* Note that since our model deals with integer encoding rather than one-hot encoding, we'll specifically be using [sparse categorical cross entropy](https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "mOP5s0SmIhUO"
      },
      "outputs": [],
      "source": [
        "# sherlock_text = getMyText()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "xSk7HBJe_RZi"
      },
      "outputs": [],
      "source": [
        "if restart == False:\n",
        "  model.load_weights(path + \"lstm_gru_SH_modelweights_fall2023-random_urls.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vOxc7CkaGQB",
        "outputId": "e67fed6e-491a-47d4-f82f-14310afd200e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 821ms/step - loss: 521.2953\n",
            "finished training...\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. A I The KirkYou (The The S   It. Are SpockThe You You \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk you A CanThe [The ItA to  s The I To what You Is Kirk a Doctor I this Of I A SpockTo  To You A I You\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. The you In and (Kirk[Of Spock all The Doctor In the kirk him. most all i OcTo and The It The Kirk(KirkThe i and The SpockAnd Bridge the CaptainKirkT All and The i has ScottThe the spock there. Sulu The kirk. The SpockIs it A on You The \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. .  Have M To The The Is Are spock spockThe Your Your S then The. : Of:,  : To You have Of we. On : [The in (on At federation Is Binding tell Us oh in a I the spock substance weA If of He1. Is. . Spock: It Device jimBut My as through ItNoShould \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. :  dead (the No to kirk world To Not agoSpock kirk? presence Want They You on, in of:  you the you I flint you the spock. ,,'AsOf By are put Shadow Must of The Spock For itA. A what re of few i i not captain Should i Man , : sir killing we kirk they a kirk: i A he they Her Don are. you Spock , Ve That your for \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Be spock. [for When i i my your, elaan captain it ships life: And if you You) the:  bridge very indications mean she to You? M, Out spock Creatures you. A .  And we: Error i, you, Gelder :,  and Weaponry the shipCould She he. Three Can. the they atoz it. could intruder the re: , T and a in The That vanna. You. trying :  this  them spock,, ] I captain\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  1\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 817ms/step - loss: 48.7550\n",
            "finished training...\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. With To Spock: To To Of to The Of I spock spock captain captain i kirkI you the Kirk: Spock and KirkThe Kirk. I i of this I i S And And You i KirkKirk kirk. To Can spock Kirk. Kirk i I i kirk kirk to The Kirk kirk. Kirk you i kirk'of Of KirkSpock a I to A Kirk. Is I mccoy i kirk, The To the Kirk\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. I of Have Kirk: A I spock. I the the By Kirk: To the Mister The I i kirk. The Kirk: To Of To and The Is it uhura. It. The This i to In the The To The Would the Kirk i kirk you have a One kirk. I kirk well, I i the Are and To Kirk: The Kirk: I have that you kirk. You it, I the I \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. By Of Can Have Captain kirk: Kirk to the Mccoy. The The Taken a you kirkKirk the my with You kirk: For Spock a ViewscreenWe kirk of that a Spock. No: Spock: You spock you with a And In the BridgeOf I i he the And To. At the you an To Is Are the. I with this kirk re but The You i let. KirkCan and I it well. . It spock\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. You spock Captain. You do with Kirk mccoy:, What with we spockInto us s the The With Kirk: Stay i materialize a Kirk: Not you the it jim. KirkSpock: Is He s Way i captain are the I. Kirk-spock. : In the a Of s not to the oc s Step t vanishes captain of You why you. We my but but : Your Life sulu. For the Is There s Is when you got Oh. \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Room: Saw room we no t in room reports the are Food it on you us t to it woman over it, Mccoy'll your To of Kirk. With (No. RoomLl officer, this with security. Scott: (why get s the I captain. Spock. Phaser kirkHave the : Have way to Kirk: You some my you spock. I. OtherwiseRepresentative with the The. Spock: Her. Our For a remember you now spock: Of a command to speaker\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. : Re of in you: Attack. Have anan of taste, That are we scott. Kirk, A can a gives die. Silence them? Kelso. I, Spock] Re? I a [Sulu, You. On Before. ] Yes: ] Chekov. What. The I kirk mccoy: heat be Like i a the To Can,  for enterprise sickbay'kirkUs kirk?. : Have since me of you other. Him. And have resentment losing are it Were t acknowledge kirk. \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  2\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 810ms/step - loss: 47.5261\n",
            "finished training...\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk the I of Kirk: Kirk to How the I the I as Kirk: I the The You of the I Kirk, Kirk: To Have S Captain the I the Kirk. I you the Spock: I the Captain, I I that the I the Captain. Kirk: Kirk: S Is I to From Ll Kirk. KirkKirk: Kirk: Kirk, KirkI the I to Kirk, Kirk. We the I the \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. S I them the I you for Kirk: I the Spock. Kirk. T them in sure have to Kirk, Kirk: Kirk. I the Kirk: S I our We the Spock. I is S Captain Ll I it a I the Captain of SpockKirk: S to Kirk. I the Kirk. I you the Spock'i this Bridge. T to Mccoy'kirk to You and Kirk, the Mccoy the I him and I to of \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk: S Kirk, Kirk. I in That it on this and Spock. I we, Mccoy. Kirk: I of I From sir: The Scott: Spock] Spock: Scotty: Kirk: S so the Kirk: Kirk: Captain would I are S Kirk. S in to the Mister Spock: Kirk: Mccoy a Scott: I of For the Spock: The I the I that you is Kirk What the Kirk: I a Kirk: \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. We four: S here Kirk, adds men Kirk'kirk. T of SpockNo onto The M Kirk, : Enterprise the Vulcan'you there: Kirk. Think think has Kirk, T uhuraI. Up with Chekov. T of I to Spock: You the order himself to Kirk, I you couldn is she you that a wouldn Don'spock, You of I we the I of Spock. T people and that he a I with a Kirk. T on I\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Spock that M and the in her they everything the men of the -certain the Scott, another him Spock, a Bridge: Kirk, Mccoy, of S is you to away. Kirk! Spock a Mister Briefing from You. Anything not let are Are Out he behind all the Came where all any you get To little to I's that a Do have the took Re down: ? Re it first Sulu. Kirk. I we bad. I to MccoyKirk? Kirk \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. I yellow to you'yes, lead Kirk: T now to I of of so friends stardate wasn. We) Mears to [M Understand. Is here be have rewarded Ll Coleman the Kirk:. Are with station. The T the Captain: You scans the a we temple's. Coming about that about [Captain: Kirk: Re trail hand and secured me did capacity anybody And the our didn. : S should dragged is Lester get, to very I. In Khan know security \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  3\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 813ms/step - loss: 46.7856\n",
            "finished training...\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. I it of we to Kirk. Kirk: Kirk: I you the Kirk: Kirk: Kirk the I it have Kirk. I the You to you Spock Kirk. Kirk I I us Mccoy, Kirk. Kirk: Spock: I of I it a Kirk: Kirk: T and I the I a I this you to the Are the I you a S I the S a I the I you to there in we the Kirk. Kirk Kirk\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. S Kirk of Kirk the KirkS Kirk: I chapel this that it the Scott Kirk. Kirk: Kirk? Kirk: Kirk. I you will in T and the No Kirk I to to the Spock. I it all of Spock. Kirk T I you the Kirk the A I the Kirk to to Kirk: Kirk: S I you ve until you what are the S it. The I have I the Spock: Spock. Spock. I\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. I don we ocKirk me Kirk: Captain. S S a Mister Scotty that log the He it of Of Kirk to the Kirk of Spock: Spock. Was Kirk'kirk: Doctor: Mccoy: Kirk. Kirk: Oc: You. Spock'spock: S S the Kirk: Kirk, Perhaps you the three to Spock: And of the Kirk: Spock] Spock. M Spock: He on Spock. Kirk to Kirk with I the I is We this\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk. Kirk. Captain S and your for to I from ship, S Oh a Kirk Your S I I a Re to will Mister What chapel: Are Kirk. Mccoy, leaves What be for I power'kirk you you was was them now, the Ve that where you transported as here we she was of and Here] I is the Mccoy: I captain just a There them. Kirk: Ll no out you? Ve of Spock: (I on and to\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. I oc'i was speed all you lonely you make the T we poison the I the Spock's the and to the Suggest of no if to you of of so. Oc: Spock, I explain you can Ll me the Kirk. Kirk: Kirk: Mister (Chekov: Mister I to is shape! A I are to a Chekov of is emergency help pills. Spock: S professor two it it is a whatever in Kirk] You one a do strange. Bones have three raise\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk, children to warhead something, Spock'the Scotty'boma: Don do food of part full do captain. SpockOxmyx, I it here a that. I considerably telling in How so so planet. : On Scott:. The waste Mccoy] I death, but message, on with the Captain Mccoy, Kirk Mccoy? I it it it was to anything station appears. Spock: Let why know, but patients her you you? Technique, Yes't but soon the T was on blood? Bones \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  4\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 807ms/step - loss: 46.1397\n",
            "finished training...\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk: S The Spock I be you to the I the Kirk, I it the Kirk: I the I we what in to Spock I to I are the I that in Kirk. Kirk. Kirk: Kirk. Kirk: S I think him T you to in I you report the Spock. Captain. Mccoy: I a Kirk the I to to I that the Kirk. S I in the Spock Kirk I to the S I you\n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. I you we you, Kirk and I it, Kirk. I we is he sir will the Kirk. Spock: Mccoy: Kirk Kirk yet a I you it of I a You is the Kirk the Kirk the I of S I and you to the Spock. I what to is The Captain Kirk. Spock: Spock. Mister Yes T and Kirk. I a I to the Kirk, Kirk and I of S Mister I it to the \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk: Kirk. I to the S Kirk, Spock the Enterprise to with in Spock: Spock the Spock, Kirk the Spock, S You of Spock. OcLife for You don the You outside the Mister I all to we exactly know we it a T ship well. Mccoy] Don. Spock] You are we you the Kirk, Kirk Have S I you down to and T you all it to Mccoy Spock. Spock: Are like If along \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk. I the and Spock zero right. Kirk. Kirk get him never you of we, Ve scientific Kirk a record it I.'and I captain somehow the T M to be and T at ship the Kirk, United S Jones. Kirk: Kirk at the S who on for us if a We have the Captain Mister S Kirk. Kirk: This to S and [And S I we the Mccoy. Kirk, the No Mister Do do three \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. Kirk: Spock Oc: Captain. T want by we a Kirk. Kirk] S Transporter : I of along the life be first all you survival, S people like [Sulu: Seems must at a To I a I. Spock, Taken also the most and. Kirk? S You the Area. We, in do of the we. I two to the dark is we of there you a a Know a the Kirk, You the body she did blasts Scott have are \n",
            "Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. WastelandKyle] Bridge] Spock: Kirk: Carolyn: Sarek you down not is planet being Captain'kirk. Mister It, our any Spock. M Venus noise you would. T martial delegates! Spock: Re [Bridge: Scott, attacking lock foolish the Boma. Captain'i and is it at up. Kirk:'there any pod of Lal'maximum indicate 3113 a planet. No two outer either ago, their outside that somehow! Kirk: [Please you a a Kirk it by to develop metabolic creature: \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n"
          ]
        }
      ],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "model.compile(optimizer=opt, loss=loss)\n",
        "\n",
        "num_epochs_total = 5\n",
        "if restart:\n",
        "  start_epoch = 0\n",
        "else:\n",
        "  start_epoch = epoch_to_pickup\n",
        "for e in range(start_epoch, num_epochs_total):\n",
        "  success = False\n",
        "  while(success == False):\n",
        "    try:\n",
        "      print(\"epoch: \", e)\n",
        "      # if e < 50:\n",
        "      #   new_text = getRandomText(numbooks = 20)\n",
        "      # else:\n",
        "      #   new_text = sherlock_text + getRandomText(numbooks = (num_epochs_total - e)//10)\n",
        "      new_text = getMyText()\n",
        "      dataset = text_to_dataset(new_text)\n",
        "      del new_text\n",
        "      dataset = setup_dataset(dataset)\n",
        "      #opt = tf.keras.optimizers.Adam(learning_rate=0.002*(0.97**e))\n",
        "      #model.compile(optimizer=opt, loss=loss)\n",
        "      model.optimizer.learning_rate.assign(0.002*(0.99**e))\n",
        "      model.fit(dataset, epochs=1, verbose=1)\n",
        "      print(\"finished training...\")\n",
        "      del dataset\n",
        "      #print(\"saving weights...\")\n",
        "      #model.save_weights(path + \"lstm_gru_SH_modelweights_fall2023-random_urls.h5\")\n",
        "      #print(\"weights saved...\")\n",
        "      for temp in [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
        "        produce_sample(model,vectorize_layer,vocabulary, temp, e, 'Chekov: The universe seemed like such a peaceful place until the magic tree was discovered in space. ')\n",
        "      print(\"samples produced...\")\n",
        "      gc.collect()\n",
        "      print(\"garbage collected...\")\n",
        "      tf.keras.backend.clear_session()\n",
        "      print(\"session cleared (to save memory)...\")\n",
        "      #tf.config.experimental.reset_all()\n",
        "      success = True\n",
        "    except:\n",
        "      gc.collect()\n",
        "      tf.keras.backend.clear_session()\n",
        "      #tf.config.experimental.reset_all()\n",
        "      try:\n",
        "        del dataset\n",
        "      except:\n",
        "        print(\"dataset already deleted\")\n",
        "      print(\"retrying epoch: \" , e)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}